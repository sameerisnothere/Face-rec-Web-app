{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to the ZIP file\n",
    "zip_file_path = 'DL_Dataset.zip'  # Update with your file path\n",
    "\n",
    "# Directory to extract images\n",
    "extracted_dir = 'extracted_images'\n",
    "\n",
    "# Create directory for extracted images\n",
    "os.makedirs(extracted_dir, exist_ok=True)\n",
    "\n",
    "# Extract images from ZIP file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_dir)\n",
    "\n",
    "# Path to the extracted training images directory\n",
    "train_dir = os.path.join(extracted_dir, 'Train1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of Train1 directory:\n",
      "Root: DL_Dataset\\Train1, Directories: ['Abdullah(ABD)', 'Abdur Rehman Durani', 'Abdur Rehman Sajid', 'Adeen Amir', 'Affan Ali Khan', 'Ahmad Ali Abid', 'Ahmad Fareed sukhera', 'Ali Inayat', 'Arsal Sheikh', 'Basim Mehmood', 'Eman Anjum', 'Faizan Haq', 'Farwa Toor', 'Hammad Anwar', 'Hamza Ahmed Zuberi', 'Hamza Wajid', 'Haya Noor', 'Itba Malahat', 'Lailoma Noor', 'Mia Akbar Jaan', 'Mujtaba', 'Omar Khan', 'Raja', 'Rehan Riaz', 'Saadullah', 'Sameer Shehzad', 'Sheharyar Sadiq', 'Sherry', 'Syed Ibrahim Hamza', 'Talha Wajid', 'Tehrim Ahmed', 'Umair', 'Umer Tayyab', 'Zaid Bin Muzammil', 'Zaid Dandia'], Files: []\n",
      "Root: DL_Dataset\\Train1\\Abdullah(ABD), Directories: [], Files: ['Screenshot 2024-05-04 192409.png', 'Screenshot 2024-05-04 192429.png', 'Screenshot 2024-05-04 192449.png', 'Screenshot 2024-05-04 192503.png']\n",
      "Root: DL_Dataset\\Train1\\Abdur Rehman Durani, Directories: [], Files: ['Screenshot 2024-05-04 195259.png', 'Screenshot 2024-05-04 195306.png']\n",
      "Root: DL_Dataset\\Train1\\Abdur Rehman Sajid, Directories: [], Files: ['Screenshot 2024-05-04 192257.png', 'Screenshot 2024-05-04 192311.png', 'Screenshot 2024-05-04 192323.png']\n",
      "Root: DL_Dataset\\Train1\\Adeen Amir, Directories: [], Files: ['Screenshot 2024-05-03 202816.png', 'Screenshot 2024-05-03 203553.png']\n",
      "Root: DL_Dataset\\Train1\\Affan Ali Khan, Directories: [], Files: ['Screenshot 2024-05-04 012324.png', 'Screenshot 2024-05-04 012336.png', 'Screenshot 2024-05-04 012346.png', 'Screenshot 2024-05-04 012401.png', 'Screenshot 2024-05-04 012414.png', 'Screenshot 2024-05-04 012426.png']\n",
      "Root: DL_Dataset\\Train1\\Ahmad Ali Abid, Directories: [], Files: ['Screenshot 2024-05-03 161509.png', 'Screenshot 2024-05-03 174110.png', 'Screenshot 2024-05-04 194905.png', 'Screenshot 2024-05-04 194911.png', 'Screenshot 2024-05-04 194916.png', 'Screenshot 2024-05-04 194929.png', 'Screenshot 2024-05-04 194936.png', 'Screenshot 2024-05-04 194942.png']\n",
      "Root: DL_Dataset\\Train1\\Ahmad Fareed sukhera, Directories: [], Files: ['Screenshot 2024-05-04 003313.png', 'Screenshot 2024-05-04 003322.png', 'Screenshot 2024-05-04 003331.png', 'Screenshot 2024-05-04 003339.png', 'Screenshot 2024-05-04 003348.png']\n",
      "Root: DL_Dataset\\Train1\\Ali Inayat, Directories: [], Files: ['Screenshot 2024-05-04 014416.png', 'Screenshot 2024-05-04 014425.png', 'Screenshot 2024-05-04 014437.png']\n",
      "Root: DL_Dataset\\Train1\\Arsal Sheikh, Directories: [], Files: ['Screenshot 2024-05-04 154906.png', 'Screenshot 2024-05-04 154917.png', 'Screenshot 2024-05-04 154935.png', 'Screenshot 2024-05-04 154945.png', 'Screenshot 2024-05-04 154957.png']\n",
      "Root: DL_Dataset\\Train1\\Basim Mehmood, Directories: [], Files: ['Screenshot 2024-05-04 212540.png', 'Screenshot 2024-05-04 212549.png', 'Screenshot 2024-05-04 212556.png']\n",
      "Root: DL_Dataset\\Train1\\Eman Anjum, Directories: [], Files: ['Screenshot 2024-05-03 161139.png', 'Screenshot 2024-05-04 154208.png', 'Screenshot 2024-05-04 154220.png', 'Screenshot 2024-05-04 154235.png', 'Screenshot 2024-05-04 154303.png', 'Screenshot 2024-05-04 154326.png', 'Screenshot 2024-05-04 154402.png']\n",
      "Root: DL_Dataset\\Train1\\Faizan Haq, Directories: [], Files: ['Screenshot 2024-05-04 154118.png', 'Screenshot 2024-05-04 154127.png']\n",
      "Root: DL_Dataset\\Train1\\Farwa Toor, Directories: [], Files: ['Screenshot 2024-05-03 203800.png', 'Screenshot 2024-05-04 193015.png', 'Screenshot 2024-05-04 193024.png', 'Screenshot 2024-05-04 193034.png']\n",
      "Root: DL_Dataset\\Train1\\Hammad Anwar, Directories: [], Files: ['Screenshot 2024-05-03 203425.png', 'Screenshot 2024-05-03 203442.png', 'Screenshot 2024-05-04 215534.png']\n",
      "Root: DL_Dataset\\Train1\\Hamza Ahmed Zuberi, Directories: [], Files: ['Screenshot 2024-05-04 155049.png', 'Screenshot 2024-05-04 155057.png', 'Screenshot 2024-05-04 155105.png', 'Screenshot 2024-05-04 155113.png', 'Screenshot 2024-05-04 155122.png']\n",
      "Root: DL_Dataset\\Train1\\Hamza Wajid, Directories: [], Files: ['Screenshot 2024-05-03 161334.png', 'Screenshot 2024-05-03 172846.png', 'Screenshot 2024-05-04 003624.png', 'Screenshot 2024-05-04 003634.png', 'Screenshot 2024-05-04 005659.png', 'Screenshot 2024-05-04 161035.png', 'Screenshot 2024-05-04 161110.png', 'Screenshot 2024-05-04 161132.png']\n",
      "Root: DL_Dataset\\Train1\\Haya Noor, Directories: [], Files: ['Screenshot 2024-05-03 203809.png', 'Screenshot 2024-05-04 155151.png', 'Screenshot 2024-05-04 155158.png', 'Screenshot 2024-05-04 161454.png', 'Screenshot 2024-05-04 215826.png', 'Screenshot 2024-05-04 215832.png']\n",
      "Root: DL_Dataset\\Train1\\Itba Malahat, Directories: [], Files: ['Screenshot 2024-05-03 161704.png', 'Screenshot 2024-05-03 174215.png', 'Screenshot 2024-05-04 155417.png', 'Screenshot 2024-05-04 155424.png', 'Screenshot 2024-05-04 155432.png', 'Screenshot 2024-05-04 155438.png', 'Screenshot 2024-05-04 155447.png']\n",
      "Root: DL_Dataset\\Train1\\Lailoma Noor, Directories: [], Files: ['Screenshot 2024-05-03 160844.png', 'Screenshot 2024-05-03 174229.png', 'Screenshot 2024-05-04 155300.png', 'Screenshot 2024-05-04 155309.png', 'Screenshot 2024-05-04 155317.png', 'Screenshot 2024-05-04 155328.png', 'Screenshot 2024-05-04 155335.png', 'Screenshot 2024-05-04 155343.png']\n",
      "Root: DL_Dataset\\Train1\\Mia Akbar Jaan, Directories: [], Files: ['Screenshot 2024-05-04 003007.png', 'Screenshot 2024-05-04 003016.png', 'Screenshot 2024-05-04 003030.png', 'Screenshot 2024-05-04 003040.png', 'Screenshot 2024-05-04 003050.png', 'Screenshot 2024-05-04 003942.png']\n",
      "Root: DL_Dataset\\Train1\\Mujtaba, Directories: [], Files: ['Screenshot 2024-05-04 013552.png', 'Screenshot 2024-05-04 013605.png', 'Screenshot 2024-05-04 013617.png', 'Screenshot 2024-05-04 013629.png', 'Screenshot 2024-05-04 013641.png', 'Screenshot 2024-05-04 013651.png']\n",
      "Root: DL_Dataset\\Train1\\Omar Khan, Directories: [], Files: ['Screenshot 2024-05-04 192735.png', 'Screenshot 2024-05-04 192746.png', 'Screenshot 2024-05-04 192759.png', 'Screenshot 2024-05-04 192808.png', 'Screenshot 2024-05-04 192819.png']\n",
      "Root: DL_Dataset\\Train1\\Raja, Directories: [], Files: ['Screenshot 2024-05-04 193153.png', 'Screenshot 2024-05-04 193210.png', 'Screenshot 2024-05-04 193218.png', 'Screenshot 2024-05-04 193227.png']\n",
      "Root: DL_Dataset\\Train1\\Rehan Riaz, Directories: [], Files: ['Screenshot 2024-05-03 203620.png', 'Screenshot 2024-05-03 203628.png', 'Screenshot 2024-05-04 004642.png', 'Screenshot 2024-05-04 004650.png', 'Screenshot 2024-05-04 004659.png', 'Screenshot 2024-05-04 004727.png', 'Screenshot 2024-05-04 004739.png']\n",
      "Root: DL_Dataset\\Train1\\Saadullah, Directories: [], Files: ['saad (12).jpg', 'Screenshot 2024-05-03 173320.png', 'Screenshot 2024-05-03 173342.png', 'Screenshot 2024-05-03 173402.png', 'Screenshot 2024-05-03 173419.png']\n",
      "Root: DL_Dataset\\Train1\\Sameer Shehzad, Directories: [], Files: ['Screenshot 2024-05-04 200127.png', 'Screenshot 2024-05-04 200134.png', 'Screenshot 2024-05-04 200140.png', 'Screenshot 2024-05-04 200147.png', 'Screenshot 2024-05-04 200157.png']\n",
      "Root: DL_Dataset\\Train1\\Sheharyar Sadiq, Directories: [], Files: ['Screenshot 2024-05-04 194239.png', 'Screenshot 2024-05-04 194245.png', 'Screenshot 2024-05-04 194251.png', 'Screenshot 2024-05-04 194256.png']\n",
      "Root: DL_Dataset\\Train1\\Sherry, Directories: [], Files: ['Screenshot 2024-05-03 174056.png', 'Screenshot 2024-05-03 202827.png', 'Screenshot 2024-05-03 203334.png', 'Screenshot 2024-05-03 203404.png', 'Screenshot 2024-05-04 215002.png', 'Screenshot 2024-05-04 215009.png', 'Screenshot 2024-05-04 215016.png']\n",
      "Root: DL_Dataset\\Train1\\Syed Ibrahim Hamza, Directories: [], Files: ['Screenshot 2024-05-04 012000.png', 'Screenshot 2024-05-04 012020.png', 'Screenshot 2024-05-04 012117.png', 'Screenshot 2024-05-04 012211.png', 'Screenshot 2024-05-04 012232.png', 'Screenshot 2024-05-04 193335.png', 'Screenshot 2024-05-04 193345.png']\n",
      "Root: DL_Dataset\\Train1\\Talha Wajid, Directories: [], Files: ['Screenshot 2024-05-04 154727.png', 'Screenshot 2024-05-04 154735.png', 'Screenshot 2024-05-04 154743.png', 'Screenshot 2024-05-04 154750.png', 'Screenshot 2024-05-04 154800.png']\n",
      "Root: DL_Dataset\\Train1\\Tehrim Ahmed, Directories: [], Files: ['Screenshot 2024-05-04 154530.png', 'Screenshot 2024-05-04 154549.png', 'Screenshot 2024-05-04 212646.png', 'Screenshot 2024-05-04 212658.png']\n",
      "Root: DL_Dataset\\Train1\\Umair, Directories: [], Files: ['Screenshot 2024-05-04 013755.png', 'Screenshot 2024-05-04 013805.png', 'Screenshot 2024-05-04 013814.png']\n",
      "Root: DL_Dataset\\Train1\\Umer Tayyab, Directories: [], Files: ['Screenshot 2024-05-04 192536.png', 'Screenshot 2024-05-04 192546.png', 'Screenshot 2024-05-04 192604.png']\n",
      "Root: DL_Dataset\\Train1\\Zaid Bin Muzammil, Directories: [], Files: ['Screenshot 2024-05-03 174623.png', 'Screenshot 2024-05-03 201324.png', 'Screenshot 2024-05-03 201340.png', 'Screenshot 2024-05-03 201421.png', 'Screenshot 2024-05-03 201433.png']\n",
      "Root: DL_Dataset\\Train1\\Zaid Dandia, Directories: [], Files: ['Screenshot 2024-05-04 155730.png', 'Screenshot 2024-05-04 155745.png', 'Screenshot 2024-05-04 161406.png', 'Screenshot 2024-05-04 161433.png']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to the uploaded ZIP file\n",
    "zip_file_path = 'DL_Dataset.zip'  # Update with the path where you uploaded DL_Dataset.zip\n",
    "\n",
    "# Directory to extract the contents\n",
    "extracted_dir = 'DL_Dataset'  # Update with the desired extraction directory path\n",
    "\n",
    "# Create a directory for extracted contents\n",
    "os.makedirs(extracted_dir, exist_ok=True)\n",
    "\n",
    "# Extract the contents of the ZIP file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all contents to the extraction directory\n",
    "    zip_ref.extractall(extracted_dir)\n",
    "\n",
    "# Path to the extracted Train1 directory\n",
    "train_dir = os.path.join(extracted_dir, 'Train1')\n",
    "\n",
    "# Verify the contents of the Train1 directory\n",
    "print(f\"Contents of Train1 directory:\")\n",
    "for root, dirs, files in os.walk(train_dir):\n",
    "    print(f\"Root: {root}, Directories: {dirs}, Files: {files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded samples: 35\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "\n",
    "# Function to load and encode sample images for each person\n",
    "def load_and_encode_samples(folder_path):\n",
    "    samples = {}  # Dictionary to store person name to face encoding mapping\n",
    "\n",
    "    # Iterate over each subfolder (person) in the training directory\n",
    "    for person_folder in sorted(os.listdir(folder_path)):\n",
    "        person_folder_path = os.path.join(folder_path, person_folder)\n",
    "\n",
    "        if os.path.isdir(person_folder_path):\n",
    "            # Find the first image file in the person's folder\n",
    "            found_face = False\n",
    "            for filename in sorted(os.listdir(person_folder_path)):\n",
    "                image_path = os.path.join(person_folder_path, filename)\n",
    "                try:\n",
    "                    # Load the image using face_recognition (RGB format)\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    \n",
    "                    # Detect faces in the image\n",
    "                    face_locations = face_recognition.face_locations(image)\n",
    "                    \n",
    "                    if len(face_locations) == 1:\n",
    "                        # Encode the face (assuming one face per image)\n",
    "                        face_encoding = face_recognition.face_encodings(image, face_locations)[0]\n",
    "                        \n",
    "                        # Store the face encoding in the dictionary\n",
    "                        samples[person_folder] = face_encoding\n",
    "                        found_face = True\n",
    "                        break  # Stop after processing the first valid image\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {filename}: {str(e)}\")\n",
    "            \n",
    "            if not found_face:\n",
    "                print(f\"No valid face found in images for {person_folder}\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "# Load and encode sample faces from the Train1 dataset\n",
    "sample_encodings = load_and_encode_samples(train_dir)\n",
    "\n",
    "# Display the number of loaded samples\n",
    "print(f\"Number of loaded samples: {len(sample_encodings)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import face_recognition\n",
    "import os\n",
    "\n",
    "# Initialize the MTCNN detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# Load and preprocess the target image (image1.jpg)\n",
    "target_image_path = 'image1.jpg'  # Update with the path to your target image\n",
    "target_image = cv2.imread(target_image_path)\n",
    "target_image_rgb = cv2.cvtColor(target_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Detect faces using MTCNN\n",
    "result = detector.detect_faces(target_image_rgb)\n",
    "\n",
    "# Initialize lists to store face locations and encodings\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "\n",
    "if result:\n",
    "    # Extract face locations from MTCNN results\n",
    "    for face_data in result:\n",
    "        bounding_box = face_data['box']\n",
    "        face_locations.append((bounding_box[1], bounding_box[0] + bounding_box[2], bounding_box[1] + bounding_box[3], bounding_box[0]))\n",
    "\n",
    "    # Extract face encodings from the target image\n",
    "    face_encodings = face_recognition.face_encodings(target_image_rgb, face_locations)\n",
    "\n",
    "# Load and encode sample faces from the Train1 dataset\n",
    "def load_and_encode_samples(folder_path):\n",
    "    samples = {}  # Dictionary to store person name to face encoding mapping\n",
    "\n",
    "    # Iterate over each subfolder (person) in the training directory\n",
    "    for person_folder in sorted(os.listdir(folder_path)):\n",
    "        person_folder_path = os.path.join(folder_path, person_folder)\n",
    "\n",
    "        if os.path.isdir(person_folder_path):\n",
    "            # Find the first valid image file in the person's folder\n",
    "            found_face = False\n",
    "            for filename in sorted(os.listdir(person_folder_path)):\n",
    "                image_path = os.path.join(person_folder_path, filename)\n",
    "                try:\n",
    "                    # Load the image using face_recognition (RGB format)\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    \n",
    "                    # Detect faces in the image\n",
    "                    face_locations = face_recognition.face_locations(image)\n",
    "                    \n",
    "                    if len(face_locations) == 1:\n",
    "                        # Encode the face (assuming one face per image)\n",
    "                        face_encoding = face_recognition.face_encodings(image, face_locations)[0]\n",
    "                        \n",
    "                        # Store the face encoding in the dictionary\n",
    "                        samples[person_folder] = face_encoding\n",
    "                        found_face = True\n",
    "                        break  # Stop after processing the first valid image\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {filename}: {str(e)}\")\n",
    "            \n",
    "            if not found_face:\n",
    "                print(f\"No valid face found in images for {person_folder}\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "# Path to the extracted Train1 directory\n",
    "train_dir = 'DL_Dataset/Train1'  # Update with the path to your Train1 directory\n",
    "\n",
    "# Load and encode sample faces from the Train1 dataset\n",
    "sample_encodings = load_and_encode_samples(train_dir)\n",
    "\n",
    "# Initialize a dictionary to store recognized names for each face\n",
    "recognized_names = {}\n",
    "\n",
    "# Compare each detected face encoding with sample face encodings\n",
    "for face_encoding, (top, right, bottom, left) in zip(face_encodings, face_locations):\n",
    "    # Initialize the recognized name as 'Unknown' by default\n",
    "    recognized_name = 'Unknown'\n",
    "\n",
    "    # Compare the face encoding with sample face encodings\n",
    "    for name, sample_encoding in sample_encodings.items():\n",
    "        # Compare the face encoding with the sample face encoding\n",
    "        match = face_recognition.compare_faces([sample_encoding], face_encoding, tolerance=0.5)\n",
    "\n",
    "        if match[0]:  # Check if there's a match\n",
    "            recognized_name = name\n",
    "            break  # Stop searching after finding a match\n",
    "\n",
    "    # Store recognized name for this face if not already recognized\n",
    "    if (top, right, bottom, left) not in recognized_names.values():\n",
    "        recognized_names[(top, right, bottom, left)] = recognized_name\n",
    "\n",
    "    # Draw rectangle around the face\n",
    "    cv2.rectangle(target_image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw label with name below the face\n",
    "    label_size, _ = cv2.getTextSize(recognized_name, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
    "    cv2.rectangle(target_image, (left, bottom - label_size[1] - 10), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "    cv2.putText(target_image, recognized_name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
    "\n",
    "# Display the annotated image with recognized faces\n",
    "cv2.imshow(\"Recognized Faces\", target_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
