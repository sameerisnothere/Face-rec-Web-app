{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of Train1 directory:\n",
      "Root: DL_Dataset\\Train1, Directories: ['Abdullah(ABD)', 'Abdur Rehman Durani', 'Abdur Rehman Sajid', 'Adeen Amir', 'Affan Ali Khan', 'Ahmad Ali Abid', 'Ahmad Fareed sukhera', 'Ali Inayat', 'Arsal Sheikh', 'Basim Mehmood', 'Eman Anjum', 'Faizan Haq', 'Farwa Toor', 'Hammad Anwar', 'Hamza Ahmed Zuberi', 'Hamza Wajid', 'Haya Noor', 'Itba Malahat', 'Lailoma Noor', 'Mia Akbar Jaan', 'Mujtaba', 'Omar Khan', 'Raja', 'Rehan Riaz', 'Saadullah', 'Sameer Shehzad', 'Sheharyar Sadiq', 'Sherry', 'Syed Ibrahim Hamza', 'Talha Wajid', 'Tehrim Ahmed', 'Umair', 'Umer Tayyab', 'Zaid Bin Muzammil', 'Zaid Dandia'], Files: []\n",
      "Root: DL_Dataset\\Train1\\Abdullah(ABD), Directories: [], Files: ['Screenshot 2024-05-04 192409.png', 'Screenshot 2024-05-04 192429.png', 'Screenshot 2024-05-04 192449.png', 'Screenshot 2024-05-04 192503.png']\n",
      "Root: DL_Dataset\\Train1\\Abdur Rehman Durani, Directories: [], Files: ['Screenshot 2024-05-04 195259.png', 'Screenshot 2024-05-04 195306.png']\n",
      "Root: DL_Dataset\\Train1\\Abdur Rehman Sajid, Directories: [], Files: ['Screenshot 2024-05-04 192257.png', 'Screenshot 2024-05-04 192311.png', 'Screenshot 2024-05-04 192323.png']\n",
      "Root: DL_Dataset\\Train1\\Adeen Amir, Directories: [], Files: ['Screenshot 2024-05-03 202816.png', 'Screenshot 2024-05-03 203553.png']\n",
      "Root: DL_Dataset\\Train1\\Affan Ali Khan, Directories: [], Files: ['Screenshot 2024-05-04 012324.png', 'Screenshot 2024-05-04 012336.png', 'Screenshot 2024-05-04 012346.png', 'Screenshot 2024-05-04 012401.png', 'Screenshot 2024-05-04 012414.png', 'Screenshot 2024-05-04 012426.png']\n",
      "Root: DL_Dataset\\Train1\\Ahmad Ali Abid, Directories: [], Files: ['Screenshot 2024-05-03 161509.png', 'Screenshot 2024-05-03 174110.png', 'Screenshot 2024-05-04 194905.png', 'Screenshot 2024-05-04 194911.png', 'Screenshot 2024-05-04 194916.png', 'Screenshot 2024-05-04 194929.png', 'Screenshot 2024-05-04 194936.png', 'Screenshot 2024-05-04 194942.png']\n",
      "Root: DL_Dataset\\Train1\\Ahmad Fareed sukhera, Directories: [], Files: ['Screenshot 2024-05-04 003313.png', 'Screenshot 2024-05-04 003322.png', 'Screenshot 2024-05-04 003331.png', 'Screenshot 2024-05-04 003339.png', 'Screenshot 2024-05-04 003348.png']\n",
      "Root: DL_Dataset\\Train1\\Ali Inayat, Directories: [], Files: ['Screenshot 2024-05-04 014416.png', 'Screenshot 2024-05-04 014425.png', 'Screenshot 2024-05-04 014437.png']\n",
      "Root: DL_Dataset\\Train1\\Arsal Sheikh, Directories: [], Files: ['Screenshot 2024-05-04 154906.png', 'Screenshot 2024-05-04 154917.png', 'Screenshot 2024-05-04 154935.png', 'Screenshot 2024-05-04 154945.png', 'Screenshot 2024-05-04 154957.png']\n",
      "Root: DL_Dataset\\Train1\\Basim Mehmood, Directories: [], Files: ['Screenshot 2024-05-04 212540.png', 'Screenshot 2024-05-04 212549.png', 'Screenshot 2024-05-04 212556.png']\n",
      "Root: DL_Dataset\\Train1\\Eman Anjum, Directories: [], Files: ['Screenshot 2024-05-03 161139.png', 'Screenshot 2024-05-04 154208.png', 'Screenshot 2024-05-04 154220.png', 'Screenshot 2024-05-04 154235.png', 'Screenshot 2024-05-04 154303.png', 'Screenshot 2024-05-04 154326.png', 'Screenshot 2024-05-04 154402.png']\n",
      "Root: DL_Dataset\\Train1\\Faizan Haq, Directories: [], Files: ['Screenshot 2024-05-04 154118.png', 'Screenshot 2024-05-04 154127.png']\n",
      "Root: DL_Dataset\\Train1\\Farwa Toor, Directories: [], Files: ['Screenshot 2024-05-03 203800.png', 'Screenshot 2024-05-04 193015.png', 'Screenshot 2024-05-04 193024.png', 'Screenshot 2024-05-04 193034.png']\n",
      "Root: DL_Dataset\\Train1\\Hammad Anwar, Directories: [], Files: ['Screenshot 2024-05-03 203425.png', 'Screenshot 2024-05-03 203442.png', 'Screenshot 2024-05-04 215534.png']\n",
      "Root: DL_Dataset\\Train1\\Hamza Ahmed Zuberi, Directories: [], Files: ['Screenshot 2024-05-04 155049.png', 'Screenshot 2024-05-04 155057.png', 'Screenshot 2024-05-04 155105.png', 'Screenshot 2024-05-04 155113.png', 'Screenshot 2024-05-04 155122.png']\n",
      "Root: DL_Dataset\\Train1\\Hamza Wajid, Directories: [], Files: ['Screenshot 2024-05-03 161334.png', 'Screenshot 2024-05-03 172846.png', 'Screenshot 2024-05-04 003624.png', 'Screenshot 2024-05-04 003634.png', 'Screenshot 2024-05-04 005659.png', 'Screenshot 2024-05-04 161035.png', 'Screenshot 2024-05-04 161110.png', 'Screenshot 2024-05-04 161132.png']\n",
      "Root: DL_Dataset\\Train1\\Haya Noor, Directories: [], Files: ['Screenshot 2024-05-03 203809.png', 'Screenshot 2024-05-04 155151.png', 'Screenshot 2024-05-04 155158.png', 'Screenshot 2024-05-04 161454.png', 'Screenshot 2024-05-04 215826.png', 'Screenshot 2024-05-04 215832.png']\n",
      "Root: DL_Dataset\\Train1\\Itba Malahat, Directories: [], Files: ['Screenshot 2024-05-03 161704.png', 'Screenshot 2024-05-03 174215.png', 'Screenshot 2024-05-04 155417.png', 'Screenshot 2024-05-04 155424.png', 'Screenshot 2024-05-04 155432.png', 'Screenshot 2024-05-04 155438.png', 'Screenshot 2024-05-04 155447.png']\n",
      "Root: DL_Dataset\\Train1\\Lailoma Noor, Directories: [], Files: ['Screenshot 2024-05-03 160844.png', 'Screenshot 2024-05-03 174229.png', 'Screenshot 2024-05-04 155300.png', 'Screenshot 2024-05-04 155309.png', 'Screenshot 2024-05-04 155317.png', 'Screenshot 2024-05-04 155328.png', 'Screenshot 2024-05-04 155335.png', 'Screenshot 2024-05-04 155343.png']\n",
      "Root: DL_Dataset\\Train1\\Mia Akbar Jaan, Directories: [], Files: ['Screenshot 2024-05-04 003007.png', 'Screenshot 2024-05-04 003016.png', 'Screenshot 2024-05-04 003030.png', 'Screenshot 2024-05-04 003040.png', 'Screenshot 2024-05-04 003050.png', 'Screenshot 2024-05-04 003942.png']\n",
      "Root: DL_Dataset\\Train1\\Mujtaba, Directories: [], Files: ['Screenshot 2024-05-04 013552.png', 'Screenshot 2024-05-04 013605.png', 'Screenshot 2024-05-04 013617.png', 'Screenshot 2024-05-04 013629.png', 'Screenshot 2024-05-04 013641.png', 'Screenshot 2024-05-04 013651.png']\n",
      "Root: DL_Dataset\\Train1\\Omar Khan, Directories: [], Files: ['Screenshot 2024-05-04 192735.png', 'Screenshot 2024-05-04 192746.png', 'Screenshot 2024-05-04 192759.png', 'Screenshot 2024-05-04 192808.png', 'Screenshot 2024-05-04 192819.png']\n",
      "Root: DL_Dataset\\Train1\\Raja, Directories: [], Files: ['Screenshot 2024-05-04 193153.png', 'Screenshot 2024-05-04 193210.png', 'Screenshot 2024-05-04 193218.png', 'Screenshot 2024-05-04 193227.png']\n",
      "Root: DL_Dataset\\Train1\\Rehan Riaz, Directories: [], Files: ['Screenshot 2024-05-03 203620.png', 'Screenshot 2024-05-03 203628.png', 'Screenshot 2024-05-04 004642.png', 'Screenshot 2024-05-04 004650.png', 'Screenshot 2024-05-04 004659.png', 'Screenshot 2024-05-04 004727.png', 'Screenshot 2024-05-04 004739.png']\n",
      "Root: DL_Dataset\\Train1\\Saadullah, Directories: [], Files: ['saad (12).jpg', 'Screenshot 2024-05-03 173320.png', 'Screenshot 2024-05-03 173342.png', 'Screenshot 2024-05-03 173402.png', 'Screenshot 2024-05-03 173419.png']\n",
      "Root: DL_Dataset\\Train1\\Sameer Shehzad, Directories: [], Files: ['Screenshot 2024-05-04 200127.png', 'Screenshot 2024-05-04 200134.png', 'Screenshot 2024-05-04 200140.png', 'Screenshot 2024-05-04 200147.png', 'Screenshot 2024-05-04 200157.png']\n",
      "Root: DL_Dataset\\Train1\\Sheharyar Sadiq, Directories: [], Files: ['Screenshot 2024-05-04 194239.png', 'Screenshot 2024-05-04 194245.png', 'Screenshot 2024-05-04 194251.png', 'Screenshot 2024-05-04 194256.png']\n",
      "Root: DL_Dataset\\Train1\\Sherry, Directories: [], Files: ['Screenshot 2024-05-03 174056.png', 'Screenshot 2024-05-03 202827.png', 'Screenshot 2024-05-03 203334.png', 'Screenshot 2024-05-03 203404.png', 'Screenshot 2024-05-04 215002.png', 'Screenshot 2024-05-04 215009.png', 'Screenshot 2024-05-04 215016.png']\n",
      "Root: DL_Dataset\\Train1\\Syed Ibrahim Hamza, Directories: [], Files: ['Screenshot 2024-05-04 012000.png', 'Screenshot 2024-05-04 012020.png', 'Screenshot 2024-05-04 012117.png', 'Screenshot 2024-05-04 012211.png', 'Screenshot 2024-05-04 012232.png', 'Screenshot 2024-05-04 193335.png', 'Screenshot 2024-05-04 193345.png']\n",
      "Root: DL_Dataset\\Train1\\Talha Wajid, Directories: [], Files: ['Screenshot 2024-05-04 154727.png', 'Screenshot 2024-05-04 154735.png', 'Screenshot 2024-05-04 154743.png', 'Screenshot 2024-05-04 154750.png', 'Screenshot 2024-05-04 154800.png']\n",
      "Root: DL_Dataset\\Train1\\Tehrim Ahmed, Directories: [], Files: ['Screenshot 2024-05-04 154530.png', 'Screenshot 2024-05-04 154549.png', 'Screenshot 2024-05-04 212646.png', 'Screenshot 2024-05-04 212658.png']\n",
      "Root: DL_Dataset\\Train1\\Umair, Directories: [], Files: ['Screenshot 2024-05-04 013755.png', 'Screenshot 2024-05-04 013805.png', 'Screenshot 2024-05-04 013814.png']\n",
      "Root: DL_Dataset\\Train1\\Umer Tayyab, Directories: [], Files: ['Screenshot 2024-05-04 192536.png', 'Screenshot 2024-05-04 192546.png', 'Screenshot 2024-05-04 192604.png']\n",
      "Root: DL_Dataset\\Train1\\Zaid Bin Muzammil, Directories: [], Files: ['Screenshot 2024-05-03 174623.png', 'Screenshot 2024-05-03 201324.png', 'Screenshot 2024-05-03 201340.png', 'Screenshot 2024-05-03 201421.png', 'Screenshot 2024-05-03 201433.png']\n",
      "Root: DL_Dataset\\Train1\\Zaid Dandia, Directories: [], Files: ['Screenshot 2024-05-04 155730.png', 'Screenshot 2024-05-04 155745.png', 'Screenshot 2024-05-04 161406.png', 'Screenshot 2024-05-04 161433.png']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to the uploaded ZIP file\n",
    "zip_file_path = 'DL_Dataset.zip'  # Update with the path where you uploaded DL_Dataset.zip\n",
    "\n",
    "# Directory to extract the contents\n",
    "extracted_dir = 'DL_Dataset'  # Update with the desired extraction directory path\n",
    "\n",
    "# Create a directory for extracted contents\n",
    "os.makedirs(extracted_dir, exist_ok=True)\n",
    "\n",
    "# Extract the contents of the ZIP file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_dir)\n",
    "\n",
    "# Path to the extracted Train1 directory\n",
    "train_dir = os.path.join(extracted_dir, 'Train1')\n",
    "\n",
    "# Verify the contents of the Train1 directory\n",
    "print(f\"Contents of Train1 directory:\")\n",
    "for root, dirs, files in os.walk(train_dir):\n",
    "    print(f\"Root: {root}, Directories: {dirs}, Files: {files}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loaded samples: 158\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def load_and_encode_samples(folder_path, scale_factor=1.0):\n",
    "    samples = {}  # Dictionary to store person name to face encoding mapping\n",
    "\n",
    "    # Iterate over each subfolder (person) in the training directory\n",
    "    for person_folder in sorted(os.listdir(folder_path)):\n",
    "        person_folder_path = os.path.join(folder_path, person_folder)\n",
    "\n",
    "        if os.path.isdir(person_folder_path):\n",
    "            # Initialize list to store face encodings for this person\n",
    "            person_encodings = []\n",
    "\n",
    "            # Iterate over each image file in the person's folder\n",
    "            for filename in sorted(os.listdir(person_folder_path)):\n",
    "                image_path = os.path.join(person_folder_path, filename)\n",
    "                try:\n",
    "                    # Load the image using OpenCV\n",
    "                    image = cv2.imread(image_path)\n",
    "                    \n",
    "                    # Resize the image if scale_factor is provided\n",
    "                    if scale_factor != 1.0:\n",
    "                        image = cv2.resize(image, (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "                    \n",
    "                    # Convert to RGB format for face recognition\n",
    "                    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    # Detect faces in the image\n",
    "                    face_locations = face_recognition.face_locations(rgb_image)\n",
    "                    \n",
    "                    if len(face_locations) > 0:\n",
    "                        # Encode all faces found in the image\n",
    "                        face_encodings = face_recognition.face_encodings(rgb_image, face_locations)\n",
    "                        person_encodings.extend(face_encodings)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {filename}: {str(e)}\")\n",
    "            \n",
    "            # Store the list of face encodings for this person in the dictionary\n",
    "            if person_encodings:\n",
    "                samples[person_folder] = person_encodings\n",
    "            else:\n",
    "                print(f\"No valid face found in images for {person_folder}\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "train_dir = 'DL_Dataset/Train1'  # Update with the path to your Train1 directory\n",
    "sample_encodings = load_and_encode_samples(train_dir, scale_factor=1.5)\n",
    "\n",
    "# Display the number of loaded samples\n",
    "print(f\"Number of loaded samples: {sum(len(encodings) for encodings in sample_encodings.values())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Recognized: Lailoma Noor, Bounding Box: (Top: 663, Right: 368, Bottom: 705, Left: 335)\n",
      "Recognized: Ahmad Ali Abid, Bounding Box: (Top: 496, Right: 714, Bottom: 532, Left: 688)\n",
      "Recognized: Affan Ali Khan, Bounding Box: (Top: 482, Right: 648, Bottom: 506, Left: 628)\n",
      "Recognized: Itba Malahat, Bounding Box: (Top: 652, Right: 266, Bottom: 694, Left: 236)\n",
      "Recognized: Abdur Rehman Sajid, Bounding Box: (Top: 424, Right: 919, Bottom: 453, Left: 896)\n",
      "Recognized: Zaid Dandia, Bounding Box: (Top: 388, Right: 1236, Bottom: 417, Left: 1213)\n",
      "Recognized: Rehan Riaz, Bounding Box: (Top: 444, Right: 780, Bottom: 466, Left: 762)\n",
      "Recognized: Arsal Sheikh, Bounding Box: (Top: 440, Right: 844, Bottom: 466, Left: 823)\n",
      "Recognized: Haya Noor, Bounding Box: (Top: 651, Right: 470, Bottom: 693, Left: 441)\n",
      "Recognized: Abdullah(ABD), Bounding Box: (Top: 401, Right: 849, Bottom: 425, Left: 830)\n",
      "Recognized: Mia Akbar Jaan, Bounding Box: (Top: 447, Right: 709, Bottom: 471, Left: 690)\n",
      "Recognized: Sameer Shehzad, Bounding Box: (Top: 443, Right: 628, Bottom: 465, Left: 610)\n",
      "Recognized: Sameer Shehzad, Bounding Box: (Top: 525, Right: 611, Bottom: 550, Left: 590)\n",
      "Recognized: Abdullah(ABD), Bounding Box: (Top: 389, Right: 1337, Bottom: 415, Left: 1313)\n",
      "Recognized: Zaid Bin Muzammil, Bounding Box: (Top: 638, Right: 169, Bottom: 676, Left: 139)\n",
      "Recognized: Basim Mehmood, Bounding Box: (Top: 417, Right: 770, Bottom: 435, Left: 755)\n",
      "Recognized: Affan Ali Khan, Bounding Box: (Top: 419, Right: 711, Bottom: 437, Left: 696)\n",
      "Recognized: Ali Inayat, Bounding Box: (Top: 382, Right: 917, Bottom: 400, Left: 900)\n",
      "Recognized: Omar Khan, Bounding Box: (Top: 393, Right: 952, Bottom: 420, Left: 930)\n",
      "Recognized: Rehan Riaz, Bounding Box: (Top: 488, Right: 571, Bottom: 509, Left: 553)\n",
      "Recognized: Ahmad Fareed sukhera, Bounding Box: (Top: 393, Right: 1049, Bottom: 415, Left: 1030)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import face_recognition\n",
    "import os\n",
    "\n",
    "# Initialize the MTCNN detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# Load and preprocess the target image (image1.jpg)\n",
    "target_image_path = 'image2.jpg'  # Update with the path to your target image\n",
    "target_image = cv2.imread(target_image_path)\n",
    "target_image_rgb = cv2.cvtColor(target_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Detect faces using MTCNN\n",
    "result = detector.detect_faces(target_image_rgb)\n",
    "\n",
    "# Initialize lists to store face locations and encodings\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "\n",
    "if result:\n",
    "    # Extract face locations from MTCNN results\n",
    "    for face_data in result:\n",
    "        bounding_box = face_data['box']\n",
    "        face_locations.append((bounding_box[1], bounding_box[0] + bounding_box[2], bounding_box[1] + bounding_box[3], bounding_box[0]))\n",
    "\n",
    "    # Extract face encodings from the target image\n",
    "    face_encodings = face_recognition.face_encodings(target_image_rgb, face_locations)\n",
    "\n",
    "# Load and encode sample faces from the Train1 dataset\n",
    "def load_and_encode_samples(folder_path):\n",
    "    samples = {}  # Dictionary to store person name to face encoding mapping\n",
    "\n",
    "    # Iterate over each subfolder (person) in the training directory\n",
    "    for person_folder in sorted(os.listdir(folder_path)):\n",
    "        person_folder_path = os.path.join(folder_path, person_folder)\n",
    "\n",
    "        if os.path.isdir(person_folder_path):\n",
    "            # Initialize list to store face encodings for this person\n",
    "            person_encodings = []\n",
    "\n",
    "            # Iterate over each image file in the person's folder\n",
    "            for filename in sorted(os.listdir(person_folder_path)):\n",
    "                image_path = os.path.join(person_folder_path, filename)\n",
    "                try:\n",
    "                    # Load the image using face_recognition (RGB format)\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    \n",
    "                    # Detect faces in the image\n",
    "                    face_locations = face_recognition.face_locations(image)\n",
    "                    \n",
    "                    if len(face_locations) == 1:\n",
    "                        # Encode the face (assuming one face per image)\n",
    "                        face_encoding = face_recognition.face_encodings(image, face_locations)[0]\n",
    "                        \n",
    "                        # Append the face encoding to the list\n",
    "                        person_encodings.append(face_encoding)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {filename}: {str(e)}\")\n",
    "            \n",
    "            # Store the list of face encodings for this person in the dictionary\n",
    "            if person_encodings:\n",
    "                samples[person_folder] = person_encodings\n",
    "            else:\n",
    "                print(f\"No valid face found in images for {person_folder}\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "# Path to the extracted Train1 directory\n",
    "train_dir = 'DL_Dataset/Train1'  # Update with the path to your Train1 directory\n",
    "\n",
    "# Load and encode sample faces from the Train1 dataset\n",
    "sample_encodings = load_and_encode_samples(train_dir)\n",
    "\n",
    "# Initialize a dictionary to store recognized names for each face\n",
    "recognized_names = {}\n",
    "\n",
    "# Compare each detected face encoding with sample face encodings\n",
    "for face_encoding, (top, right, bottom, left) in zip(face_encodings, face_locations):\n",
    "    # Initialize the recognized name as 'Unknown' by default\n",
    "    recognized_name = 'Unknown'\n",
    "\n",
    "    # Initialize minimum distance to a large value\n",
    "    min_distance = float('inf')\n",
    "\n",
    "    # Compare the face encoding with sample face encodings\n",
    "    for name, encodings_list in sample_encodings.items():\n",
    "        for sample_encoding in encodings_list:\n",
    "            # Calculate the distance between the detected face and the sample face\n",
    "            distance = face_recognition.face_distance([sample_encoding], face_encoding)[0]\n",
    "\n",
    "            # Update recognized name if distance is below threshold\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                recognized_name = name\n",
    "\n",
    "    # Store recognized name for this face\n",
    "    recognized_names[(top, right, bottom, left)] = recognized_name\n",
    "\n",
    "    # Print recognized name along with bounding box coordinates\n",
    "    print(f\"Recognized: {recognized_name}, Bounding Box: (Top: {top}, Right: {right}, Bottom: {bottom}, Left: {left})\")\n",
    "\n",
    "    # Draw rectangle around the face\n",
    "    cv2.rectangle(target_image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw label with name below the face\n",
    "    label_size, _ = cv2.getTextSize(recognized_name, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
    "    cv2.rectangle(target_image, (left, bottom - label_size[1] - 10), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "    cv2.putText(target_image, recognized_name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n",
    "\n",
    "# Display the annotated image with recognized faces\n",
    "cv2.imshow(\"Recognized Faces\", target_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "import face_recognition\n",
    "import os\n",
    "\n",
    "# Initialize the MTCNN detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# Load and preprocess the target image (image1.jpg)\n",
    "target_image_path = 'image1.jpg'  # Update with the path to your target image\n",
    "target_image = cv2.imread(target_image_path)\n",
    "target_image_rgb = cv2.cvtColor(target_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Detect faces using MTCNN\n",
    "result = detector.detect_faces(target_image_rgb)\n",
    "\n",
    "# Initialize lists to store face locations and encodings\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "\n",
    "if result:\n",
    "    # Extract face locations from MTCNN results\n",
    "    for face_data in result:\n",
    "        bounding_box = face_data['box']\n",
    "        face_locations.append((bounding_box[1], bounding_box[0] + bounding_box[2], bounding_box[1] + bounding_box[3], bounding_box[0]))\n",
    "\n",
    "    # Extract face encodings from the target image\n",
    "    face_encodings = face_recognition.face_encodings(target_image_rgb, face_locations)\n",
    "\n",
    "# Load and encode sample faces from the Train1 dataset\n",
    "def load_and_encode_samples(folder_path):\n",
    "    samples = {}  # Dictionary to store person name to face encoding mapping\n",
    "\n",
    "    # Iterate over each subfolder (person) in the training directory\n",
    "    for person_folder in sorted(os.listdir(folder_path)):\n",
    "        person_folder_path = os.path.join(folder_path, person_folder)\n",
    "\n",
    "        if os.path.isdir(person_folder_path):\n",
    "            # Find the first valid image file in the person's folder\n",
    "            found_face = False\n",
    "            for filename in sorted(os.listdir(person_folder_path)):\n",
    "                image_path = os.path.join(person_folder_path, filename)\n",
    "                try:\n",
    "                    # Load the image using face_recognition (RGB format)\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    \n",
    "                    # Detect faces in the image\n",
    "                    face_locations = face_recognition.face_locations(image)\n",
    "                    \n",
    "                    if len(face_locations) == 1:\n",
    "                        # Encode the face (assuming one face per image)\n",
    "                        face_encoding = face_recognition.face_encodings(image, face_locations)[0]\n",
    "                        \n",
    "                        # Store the face encoding in the dictionary\n",
    "                        samples[person_folder] = face_encoding\n",
    "                        found_face = True\n",
    "                        break  # Stop after processing the first valid image\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {filename}: {str(e)}\")\n",
    "            \n",
    "            if not found_face:\n",
    "                print(f\"No valid face found in images for {person_folder}\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "# Path to the extracted Train1 directory\n",
    "train_dir = 'DL_Dataset/Train1'  # Update with the path to your Train1 directory\n",
    "\n",
    "# Load and encode sample faces from the Train1 dataset\n",
    "sample_encodings = load_and_encode_samples(train_dir)\n",
    "\n",
    "# Initialize a dictionary to store recognized names for each face\n",
    "recognized_names = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compare each detected face encoding with sample face encodings\n",
    "for face_encoding, (top, right, bottom, left) in zip(face_encodings, face_locations):\n",
    "    # Initialize the recognized name as 'Unknown' by default\n",
    "    recognized_name = 'Unknown'\n",
    "    min_distance = 0.6  # Initialize minimum distance threshold\n",
    "\n",
    "    # Compare the face encoding with sample face encodings\n",
    "    for name, sample_encoding in sample_encodings.items():\n",
    "        # Calculate the distance between the detected face and the sample face\n",
    "        distance = face_recognition.face_distance([sample_encoding], face_encoding)[0]\n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            recognized_name = name\n",
    "\n",
    "    # Store recognized name for this face if not already recognized\n",
    "    if (top, right, bottom, left) not in recognized_names.values():\n",
    "        recognized_names[(top, right, bottom, left)] = recognized_name\n",
    "\n",
    "    # Draw rectangle around the face\n",
    "    cv2.rectangle(target_image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw label with name below the face\n",
    "    label_size, _ = cv2.getTextSize(recognized_name, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
    "    cv2.rectangle(target_image, (left, bottom - label_size[1] - 10), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "    cv2.putText(target_image, recognized_name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
